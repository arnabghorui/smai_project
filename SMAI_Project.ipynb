{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnabghorui/smai_project/blob/main/SMAI_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kVRMyp9XfJB"
      },
      "source": [
        "## TF IDF & MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OFWVdF2bIXB"
      },
      "source": [
        "Here we are given two articles and we have to check similarity between them,\n",
        "There are many metrics of similarity, <br>\n",
        "<br>\n",
        "One of them is TF IDF ( Total Frequency * Inverse Document Frequency). In this metric we multiply the number of times a word is present in a document to the inverse of the number of the articles that the word appears in. The inverse part shows the overall importance of the word and the frequency part shows how important the given word is in the context of the present article. <br>\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlKpcsTKlgpi"
      },
      "source": [
        "###Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEDFJv24Ua-g",
        "outputId": "05205f3f-9822-404e-9783-a49716b986da"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g5qAXYwTW_qW"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "f = open('/content/drive/MyDrive/SMAI Proj/Copy of train_data.json')\n",
        "train_data = json.load(f)\n",
        "g= open('/content/drive/MyDrive/SMAI Proj/Copy of test_data.json')\n",
        "test_data = json.load(g)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data[0].keys())\n",
        "\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EutlPCyJs28",
        "outputId": "fded3945-7c79-4240-d637-8d2a2f3e5078"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['pair_id', 'title_1', 'title_2', 'text_1', 'text_2', 'tags_1', 'tags_2', 'meta_lang_1', 'meta_lang_2', 'score'])\n",
            "4316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv1FI0grlktK"
      },
      "source": [
        "After Filtering out the english articles - we compare the two articles in a given element. \n",
        "\n",
        "For that we append the two articles with keys : text_1 and text_2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhjKY1PWlfsg",
        "outputId": "02351ed8-9ff4-4f85-a7a7-93ee7dc0cb52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2574, 25972)\n",
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "(472, 25972)\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "\n",
        "\n",
        "english_articles_train = []\n",
        "english_articles_test = []\n",
        "\n",
        "\n",
        "for d in train_data:\n",
        "  if d['meta_lang_1'] == 'en' and d['meta_lang_2'] == 'en':\n",
        "    english_articles_train.append(d)\n",
        "\n",
        "for d in test_data:\n",
        "  if d['meta_lang_1'] == 'en' and d['meta_lang_2'] == 'en':\n",
        "    english_articles_test.append(d)\n",
        "\n",
        "\n",
        "\n",
        "total_train_articles = []\n",
        "total_test_articles = []\n",
        "\n",
        "y_train = []\n",
        "y_test = []\n",
        "\n",
        "for eng in english_articles_train:\n",
        "  total_train_articles.append(eng['text_1'])\n",
        "  total_train_articles.append(eng['text_2'])\n",
        "  y_train.append(eng['score'])\n",
        "\n",
        "for eng in english_articles_test:\n",
        "  total_test_articles.append(eng['text_1'])\n",
        "  total_test_articles.append(eng['text_2'])\n",
        "  y_test.append(eng['score'])\n",
        "\n",
        "\n",
        "'''\n",
        "art1 = art1.split()\n",
        "\n",
        "art2 = art2.split()\n",
        "\n",
        "for i in range(len(art1)):\n",
        "    art1[i] = ''.join([letter for letter in art1[i] if letter not in punctuation])\n",
        "\n",
        "for i in range(len(art2)):\n",
        "    art2[i] = ''.join([letter for letter in art2[i] if letter not in punctuation])\n",
        "'''\n",
        "\n",
        "#########################################################\n",
        "\n",
        "\n",
        "\n",
        "tf = TfidfVectorizer(min_df =2)\n",
        "\n",
        "x_train = tf.fit(total_train_articles)\n",
        "x_train = tf.transform(total_train_articles)\n",
        "x_test = tf.transform(total_test_articles)\n",
        "\n",
        "\n",
        "print(x_train.shape)\n",
        "\n",
        "print(type(x_train))\n",
        "\n",
        "\n",
        "\n",
        "X_text_1_train = []\n",
        "X_text_2_train = []\n",
        "X_text_1_test = []\n",
        "X_text_2_test = []\n",
        "\n",
        "\n",
        "print(x_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for j in range(1287):\n",
        "  X_text_1_train.append(x_train[2*j])\n",
        "  X_text_2_train.append(x_train[2*j+1])\n",
        "\n",
        "for j in range(236):\n",
        "  X_text_1_test.append(x_test[2*j])\n",
        "  X_text_2_test.append(x_test[2*j+1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6pVqJRTJMu-9"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import csr_matrix\n",
        " \n",
        "\n",
        "X1_train = []\n",
        "X2_train = []\n",
        "X1_test = []\n",
        "X2_test = []\n",
        "\n",
        "for i in range(1287):\n",
        "  X1_train.append(np.array(csr_matrix.todense(X_text_1_train[i])))\n",
        "  X2_train.append(np.array(csr_matrix.todense(X_text_2_train[i])))\n",
        "\n",
        "for i in range(236):\n",
        "  X1_test.append(np.array(csr_matrix.todense(X_text_1_test[i])))\n",
        "  X2_test.append(np.array(csr_matrix.todense(X_text_2_test[i])))\n",
        "\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "#scor1 = np.reshape(scor1,(1287,1))\n",
        "X1_train = np.array(X1_train)\n",
        "X2_train = np.array(X2_train)\n",
        "X1_test = np.array(X1_test)\n",
        "X2_test = np.array(X2_test)\n",
        "\n",
        "#rows1 = np.reshape()\n",
        "\n",
        "X1_train = X1_train.reshape(1287,25972)\n",
        "X2_train = X2_train.reshape(1287,25972)\n",
        "X1_test = X1_test.reshape(236,25972)\n",
        "X2_test = X2_test.reshape(236,25972)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "5JqjMV8T9ptZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the Siamese implementation of the "
      ],
      "metadata": {
        "id": "2MfeBtBDWoKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, LSTM, Input, concatenate\n",
        "\n",
        "input_1 = Input(shape=(25972, ))\n",
        "dense_1 = Dense(1000, )(input_1)\n",
        "\n",
        "input_2 = Input(shape=(25972, ))\n",
        "dense_2 = Dense(1000, )(input_2)\n",
        "\n",
        "merge = concatenate([dense_1, dense_2])\n",
        "\n",
        "dense_3  = Dense(200,)(merge)\n",
        "dense_4  = Dense(50,)(dense_3)\n",
        "dense_all = Dense(1,)(dense_4)\n",
        "#second_dense = Dense(2, activation='softmax')(merge)\n",
        "\n",
        "model = Model(inputs=[input_1, input_2], outputs=dense_all)\n",
        "optimizer = keras.optimizers.Adam()  #learning_rate=0.001\n",
        "model.compile(loss='mse', optimizer = optimizer) #, metrics=['RootMeanSquaredError']\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "B4Uae1l-9sqb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd5878fb-f61e-4969-923b-a135c98e9596"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 25972)]      0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 25972)]      0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1000)         25973000    ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1000)         25973000    ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 2000)         0           ['dense[0][0]',                  \n",
            "                                                                  'dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 200)          400200      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 50)           10050       ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 1)            51          ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 52,356,301\n",
            "Trainable params: 52,356,301\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([X1_train, X2_train], y_train, epochs=10)"
      ],
      "metadata": {
        "id": "HWIGhpNNBxCe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a82b426-b19a-4fdc-c6b2-5a6f74479150"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "41/41 [==============================] - 3s 15ms/step - loss: 2.0922\n",
            "Epoch 2/10\n",
            "41/41 [==============================] - 1s 15ms/step - loss: 0.5736\n",
            "Epoch 3/10\n",
            "41/41 [==============================] - 1s 15ms/step - loss: 0.1385\n",
            "Epoch 4/10\n",
            "41/41 [==============================] - 1s 15ms/step - loss: 0.0521\n",
            "Epoch 5/10\n",
            "41/41 [==============================] - 1s 15ms/step - loss: 0.0270\n",
            "Epoch 6/10\n",
            "41/41 [==============================] - 1s 15ms/step - loss: 0.0254\n",
            "Epoch 7/10\n",
            "41/41 [==============================] - 1s 15ms/step - loss: 0.0256\n",
            "Epoch 8/10\n",
            "41/41 [==============================] - 1s 14ms/step - loss: 0.0378\n",
            "Epoch 9/10\n",
            "41/41 [==============================] - 1s 15ms/step - loss: 0.0409\n",
            "Epoch 10/10\n",
            "41/41 [==============================] - 1s 15ms/step - loss: 0.0377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict([X1_test,X2_test])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M_5ak-SFuo-",
        "outputId": "ea9267a3-52d1-45aa-8545-7c2e37faf776"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
        "from sklearn.feature_selection import r_regression\n",
        "print('The mean absolute error for the model is ', mean_absolute_error(y_test,y_pred))\n",
        "print('The mean squared error for the model is ', mean_squared_error(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqzRoMavQMFv",
        "outputId": "62c453ec-aa3c-402c-e4b2-7d83168dffe2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean absolute error for the model is  1.1683223929445623\n",
            "The mean squared error for the model is  1.8702846275621536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz_fZ6aBSLT8",
        "outputId": "cccdda68-588f-4c68-ddb7-9087390e6705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(236, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "print(pearsonr(y_test,y_pred))"
      ],
      "metadata": {
        "id": "nsZ1BViCSRMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7d6556-d85c-4200-c51d-ed188849a38b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0.23978364601809363], dtype=object), 0.00020043981758582774)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RHk8xRwBV2Xo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}